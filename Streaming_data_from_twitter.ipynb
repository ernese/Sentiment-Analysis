{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Streaming data from twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyoX4T9_Asw",
        "colab_type": "text"
      },
      "source": [
        "#Assigment 3: Social Network Analysis for U.S presidential elections\n",
        "<br>42913 Social and Information Network Analysis - Autumn 2020\n",
        "\n",
        "<br>Carlos Mario Carvajal Moreno. Student ID: 13144148\n",
        "<br>Andres Felipe Lagos. Student ID: 13092248\n",
        "<br>Ernest Ilustre.  Student ID: 12763239"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jutDkijLvbrn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# The Twitter API and Authentication\n",
        "\n",
        "\n",
        "To access the twitter API, it is required to have twitter developer account. With this account the following authentication credentials can be obtained and will be used for streaming tweets in python from the tweeter API:\n",
        "\n",
        "* API Key\n",
        "* API Secret\n",
        "* Access Token \n",
        "* Access Token Secret\n",
        "\n",
        "However, as the credentials belong to a personal account, the following code will not display them for privacy and security matters. To run this code, please use your own credential or contact one of the owners of this notebook to have a live demonstration.\n",
        "\n",
        "## Tweeter Streaming APIs\n",
        "\n",
        "This API will be used for straming and reading data from twitter. Any public twitter ac in particular we will use the public streams which twitter documentation defines as stream of the public data flowing through tweeter.\n",
        "\n",
        "The following code stream Tweets and retrieve the data in a JSON format that contain great number fields. However, only few will be studied by producing filterings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iWYW9lOOnRe",
        "colab_type": "code",
        "outputId": "b89bd0cd-56bd-489a-d23d-c9acbfbb1291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "pip install twython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twython\n",
            "  Downloading https://files.pythonhosted.org/packages/24/80/579b96dfaa9b536efde883d4f0df7ea2598a6f3117a6dd572787f4a2bcfb/twython-3.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1yqlBf1vTZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy, json\n",
        "import pandas as pd\n",
        "from twython import Twython\n",
        "import csv\n",
        "import os\n",
        "\n",
        "#Please use your twitter developer credentials to run this code\n",
        "access_token = \"\"\n",
        "access_token_secret = \"\"\n",
        "consumer_key = \"\"\n",
        "consumer_secret = \"\"\n",
        "\n",
        "#pass the api key and secret to the handler\n",
        "#pass the credentials using the set_access_token method\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPxHB-QTvhk3",
        "colab_type": "text"
      },
      "source": [
        "##Defining the twitter stream listener class.\n",
        "\n",
        "in the following code a twitter listener has been generated to create a file that called tweets.txt. This listener collects streaming tweets and writtes it to the file tweets.text. In it we define the number of tweets to be streamed and after it finishes streaming the tweets the listener closes the file and stops listening.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdzSoawoUu0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyStreamListener(tweepy.StreamListener):\n",
        "    def __init__(self, api=None):\n",
        "        super(MyStreamListener, self).__init__()\n",
        "        self.num_tweets = 0\n",
        "        self.file = open(\"tweets.txt\", \"w\")\n",
        "\n",
        "    def on_status(self, status):\n",
        "        tweet = status._json\n",
        "        if not tweet['retweeted'] and 'RT @' not in tweet['text']:\n",
        "          if \"extended_tweet\" in tweet:\n",
        "            if tweet['user']['followers_count'] > 1:\n",
        "              self.file.write( json.dumps(tweet) + '\\n' )\n",
        "              self.num_tweets += 1\n",
        "              if self.num_tweets < 1000000:\n",
        "                return True\n",
        "              else:\n",
        "                return False\n",
        "              self.file.close()\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E94BhTIPvnSs",
        "colab_type": "text"
      },
      "source": [
        "After writting the listener class, the streaming object needs authentication, and will be passed a query to stream tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOZlekOnIEVb",
        "colab_type": "text"
      },
      "source": [
        "## Streaming Tweets and saving them in a txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjTDJxf23svy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = MyStreamListener()\n",
        "\n",
        "key_words = ['trump', 'biden', 'maga', 'makeamericagreatagain','nevertrump','trump2020','biden2020',\n",
        "             'Joe Biden', '2020 elections', 'trump president','neverbiden', 'biden president']\n",
        "\n",
        "stream = tweepy.Stream(auth, l, tweet_mode='extended', query = {'q': '-filter:RT @',\n",
        "                                                               'language': 'en'} )\n",
        "\n",
        "stream.filter(track = key_words) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eJpQQIHvq-8",
        "colab_type": "text"
      },
      "source": [
        "The following code will set ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EO0B5quZ5Ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# String of path to file: tweets_data_path\n",
        "tweets_data_path = 'tweets.txt'\n",
        "\n",
        "# Initialize empty list to store tweets: tweets_data\n",
        "tweets_data = []\n",
        "\n",
        "# Open connection to file\n",
        "tweets_file = open(tweets_data_path, \"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyAyX-otyQgj",
        "colab_type": "code",
        "outputId": "b7fb3404-2866-4d4d-d464-3a6302c6add7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# Read in tweets and store in list: tweets_data\n",
        "for line in tweets_file:\n",
        "    tweet = json.loads(line)\n",
        "    tweets_data.append(tweet)\n",
        "\n",
        "# Close connection to file\n",
        "tweets_file.close()\n",
        "\n",
        "# Creating an empty dictionary to append the tweets\n",
        "dict_ = {'Tweet_id': [], 'User_id':[], 'user': [], 'date': [], 'text': [], 'favourites_count': [],\n",
        "         \"followers_count\": [], \"Retweet_count\":[], 'Place':[]\n",
        "         }\n",
        "\n",
        "# For loop to append data into the dictionary        \n",
        "for status in tweets_data:\n",
        "    dict_['Tweet_id'].append(status['id'])\n",
        "    dict_['user'].append(status['user']['screen_name'])\n",
        "    dict_['User_id'].append(status['user']['id_str'])\n",
        "    dict_['date'].append(status['created_at'])\n",
        "    if 'extended_tweet' in status.keys():\n",
        "      dict_['text'].append(status['extended_tweet']['full_text'])\n",
        "    else:\n",
        "      dict_['text'].append(status['text'])\n",
        "    dict_['favourites_count'].append(status['favorite_count'])\n",
        "    dict_['followers_count'].append(status['user']['followers_count'])\n",
        "    dict_['Retweet_count'].append(status['retweet_count'])\n",
        "    dict_['Place'].append(status['user']['location'])\n",
        "\n",
        "# Structure data in a pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(dict_)\n",
        "df.sort_values(by='favourites_count', inplace=True, ascending=False)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_id</th>\n",
              "      <th>User_id</th>\n",
              "      <th>user</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>favourites_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>Retweet_count</th>\n",
              "      <th>Place</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1269552454628249600</td>\n",
              "      <td>37755581</td>\n",
              "      <td>JohnHopkins_</td>\n",
              "      <td>Sun Jun 07 08:51:06 +0000 2020</td>\n",
              "      <td>@DelGeezer üëÅÔ∏è We see you there, we know what y...</td>\n",
              "      <td>0</td>\n",
              "      <td>1435</td>\n",
              "      <td>0</td>\n",
              "      <td>Liverpool UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26255</th>\n",
              "      <td>1269595199652728834</td>\n",
              "      <td>47331230</td>\n",
              "      <td>Zebra1944</td>\n",
              "      <td>Sun Jun 07 11:40:58 +0000 2020</td>\n",
              "      <td>PBOTUS=PUNK BULLY OF THE UNITED STATES=DONALD ...</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>Pennsylvania  USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26248</th>\n",
              "      <td>1269595193503858688</td>\n",
              "      <td>896904160305655808</td>\n",
              "      <td>Sherathorington</td>\n",
              "      <td>Sun Jun 07 11:40:56 +0000 2020</td>\n",
              "      <td>@dooleyynoted they don't tell you these things...</td>\n",
              "      <td>0</td>\n",
              "      <td>1952</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26249</th>\n",
              "      <td>1269595193877114882</td>\n",
              "      <td>516645637</td>\n",
              "      <td>ianbodgerbrown</td>\n",
              "      <td>Sun Jun 07 11:40:56 +0000 2020</td>\n",
              "      <td>Can Congress Impeach Trump Again For His Worst...</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>0</td>\n",
              "      <td>Manchester, UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26250</th>\n",
              "      <td>1269595195957534722</td>\n",
              "      <td>1707512646</td>\n",
              "      <td>fmiller26</td>\n",
              "      <td>Sun Jun 07 11:40:57 +0000 2020</td>\n",
              "      <td>@MZHemingway Every Democrat should be voted ou...</td>\n",
              "      <td>0</td>\n",
              "      <td>2324</td>\n",
              "      <td>0</td>\n",
              "      <td>Indiana, USA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tweet_id  ...              Place\n",
              "0      1269552454628249600  ...       Liverpool UK\n",
              "26255  1269595199652728834  ...  Pennsylvania  USA\n",
              "26248  1269595193503858688  ...               None\n",
              "26249  1269595193877114882  ...     Manchester, UK\n",
              "26250  1269595195957534722  ...       Indiana, USA\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swx-_k-o0fIZ",
        "colab_type": "code",
        "outputId": "4082867b-ec7d-47bc-f74d-a95d2f149ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34RxzxG60gm9",
        "colab_type": "code",
        "outputId": "7f4a9f68-8342-47c3-fd05-965d484291c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df['Place'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "United States                 993\n",
              "USA                           339\n",
              "Florida, USA                  280\n",
              "Texas, USA                    218\n",
              "London, England               194\n",
              "                             ... \n",
              "Wisconsin and Nevada            1\n",
              "◊ô◊©◊®◊ê◊ú                           1\n",
              "Buford, GA                      1\n",
              "Great Plains                    1\n",
              "Somewhere in space & time.      1\n",
              "Name: Place, Length: 9017, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2fFjeB1KqYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "df.to_csv('tweeter_dataset.csv')\n",
        "\n",
        "files.download('tweeter_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhwqC2aCJYih",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the most popular tweets from a region using Twython"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hDfqtzPHl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate an object\n",
        "python_tweets = Twython(consumer_key, consumer_secret)\n",
        "\n",
        "key_words = ['trump', 'biden', 'maga', 'makeamericagreatagain','nevertrump','trump2020','biden2020',\n",
        "             '2020 elections','neverbiden']\n",
        "\n",
        "result_type = ['popular','recent','mixed']\n",
        "\n",
        "list_id = []\n",
        "\n",
        " # Creating empty dictionary\n",
        "dict_ = {'Tweet_id': [], 'User_id':[], 'user': [], 'date': [], 'text': [], 'favorite_count': [], \"followers_count\": [],\n",
        "         'Retweeted': [], \"Retweet_count\":[], 'Place':[]\n",
        "         }\n",
        "\n",
        "\n",
        "for word in key_words:\n",
        "  for result in result_type:\n",
        "    for id_ in list_id:\n",
        "      query = {'q': word,\n",
        "               'result_type': result_type,\n",
        "               'count' : 100,\n",
        "               'lang': 'en',\n",
        "               'since_id': list_id}\n",
        "        \n",
        "        for status in python_tweets.search(**query, tweet_mode='extended')['statuses']:\n",
        "          dict_['Tweet_id'].append(status['id'])\n",
        "          dict_['user'].append(status['user']['screen_name'])\n",
        "          dict_['User_id'].append(status['user']['id_str'])\n",
        "          dict_['date'].append(status['created_at'])\n",
        "          dict_['text'].append(status['full_text'])\n",
        "          dict_['favorite_count'].append(status['favorite_count'])\n",
        "          dict_['followers_count'].append(status['user']['followers_count'])\n",
        "          dict_['Retweeted'].append(status['retweeted'])\n",
        "          dict_['Retweet_count'].append(status['retweet_count'])\n",
        "          dict_['Place'].append(status['user']['location'])\n",
        "\n",
        "# Structure data in a pandas DataFrame for easier manipulation\n",
        "df1 = pd.DataFrame(dict_)\n",
        "df1.sort_values(by='favorite_count', inplace=True, ascending=False)\n",
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5zrHxcgLVHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second part\n",
        "df1.to_csv('tweets.csv')\n",
        "\n",
        "files.download('tweets.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}